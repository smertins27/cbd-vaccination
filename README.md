# Hochschule Bremen - Wintersemester 2020/2021 - Module: Cloud & Big Data

## Vaccination Progress Dashboard
Fighting together the current Covid-19 crisis with our dashboard to track the vaccination progress of all German federal states.
Track the progress of the vaccinations of your federal state and get more information about the used vaccine. 

This use case is implemented by `Sebastian Mertins`, `Pascal Seegers` and `Tom Seevers`.

For a quick overview you are able to find a screencast of our application in `/documentation`.

##Idea: Dashboard for all German federal states and their vaccination progress
First we thought about a dashboard for the world vaccination progress, which presents the progress of all countries in the world.
In that use case we weren't able to achieve the Big Data character due the missing insert and update of data. So we decided to create a fictional dashboard for Germany and its federal states only.
To work with data and process them, we've planned a fictional use case for this dashboard. A user is able to add new vaccinations which are added to the vaccination progress of a federal state.
Furthermore, we added the opportunity to select between different vaccines for the vaccination progress to display the distribution of used vaccines and progress for each federal state.

## Architecture
![Architecture](https://raw.githubusercontent.com/smertins27/cbd-vaccination/master/documentation/images/Architecture.png)

For the Big Data Science application we are using a Kubernetes Cluster which is locally provided by a minikube/microk8s.
This allows us to run a scalable development structure and react to higher traffic/load by starting new instances of the web and cache server and the big data services.

The mentioned load balancer is provided by Kubernetes with an ingress and distributes the traffic to multiple webservers. In our case we are only using one webserver to keep the use case as simple as possible.
For serving the webserver application to a user, we are using NodeJS with Express for serving the content.

As shown as in the architecture picture, the web server grants its data from a cache or MySQL server. The usage of multiple cache servers, implemented by a memcached-cluster, reduce the stress of the database and allows a higher scalability of the application.
The web server doesn't insert data directly into the database. For that case there is a Kafka cluster running, which ist working as a big data message service.
That cluster docks on the Spark application, which is also running inside the same cluster. That Spark Application, computes the message data from Kafka and sends it directly into the database or the checkpoints will be stored into the Data Lake.
The Data Lake is provided by a HDFS cluster.

### Database Design
The following images gives a slight overview about our database structure.
Mainly we are using four tables, which holds the complete data of the project.
The tables `states` and `vaccines` are preloaded with content to ensure that the application runs properly.
The remaining tables are feed with dynamic user generated or batch calculated data, which are inserted via kafka and batch processing.

![Database Design](https://raw.githubusercontent.com/smertins27/cbd-vaccination/master/documentation/images/MySQL_Database.png)

### Generating data

The user generated data consists of same data which are filled with information from a simple form.
To simulate the Big Data character and to stress the batch processing a hugh amount of data entries can be randomly generated by an JavaScript function.  

```
{ 
	vaccinescode: 'bnt', 
	statesiso: 'NI',
	vac_amount: 1500,
	timestamp: 1617195643,
	percent: 0.1152568,
	vacId: 0,
	progressId: 0,
	vacAmountInDb: 0,
	percentageInDb: 0	
}
```

## Prerequisites

### Required software
To develop and deploy the project in a local Kubernetes some software requirements needs to be installed.
This case shows the commands for macOS

Minikube: `brew install minikube`

Skaffold: `brew install skaffold`

Helm: `brew install helm`

Enable ingress `minikube addons enable ingress`

A running Strimzi.io Kafka operator

```bash
helm repo add strimzi http://strimzi.io/charts/
helm install my-kafka-operator strimzi/strimzi-kafka-operator
kubectl apply -f https://farberg.de/talks/big-data/code/helm-kafka-operator/kafka-cluster-def.yaml
```

A running Hadoop cluster with YARN (for checkpointing)

```bash
helm repo add stable https://charts.helm.sh/stable
helm install --namespace=default --set hdfs.dataNode.replicas=1 --set yarn.nodeManager.replicas=1 --set hdfs.webhdfs.enabled=true my-hadoop-cluster stable/hadoop
```

## Deploy

To develop using [Skaffold](https://skaffold.dev/), use `skaffold dev`. 
